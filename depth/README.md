# ğŸ“ RailAI-Vision: Depth Fusion Module

This module performs real-time or offline fusion of **object detection**, **railway track segmentation**, and **depth estimation** using **ZED2 stereo camera** or **MiDaS monocular model**. It is a core component of the `RailAI-Vision` framework for enhancing railway environment perception and safety.

---

## ğŸ“ Folder Structure
```
depth/
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ run_depth_fusion_zed.py       # Real-time fusion using ZED2
â”‚ â””â”€â”€ run_depth_fusion_midas.py     # Offline fusion using MiDaS
â”œâ”€â”€ engine.py                       # Fusion pipeline logic
â”œâ”€â”€ models/
â”‚ â”œâ”€â”€ loader.py                     # Model loaders (YOLOv11, DeepLabV3+, MiDaS)
â”‚ â””â”€â”€ utils.py                      # Depth utility functions
â”œâ”€â”€ utils/
â”‚ â””â”€â”€ visualization.py              # Drawing, overlaying, and display utilities
â”œâ”€â”€ results/                        # Evaluation outputs: confusion matrices, prediction samples, metrics
â”œâ”€â”€ requirements.txt                # Dependencies for the detection module
â””â”€â”€ README.md                       # This documentation file                     # Documentation and usage guide
```

---

## ğŸš€ Functionality Overview

| Feature                   | ZED2 Mode (`run_depth_fusion_zed.py`) | MiDaS Mode (`run_depth_fusion_midas.py`) |
|---------------------------|---------------------------------------|------------------------------------------|
| Real-time Inference       | âœ…                                     | âŒ (offline only)                         |
| Monocular Depth Support   | âŒ                                     | âœ…                                        |
| Stereo Depth Support      | âœ…                                     | âŒ                                        |
| Detection (YOLOv11)       | âœ…                                     | âœ…                                        |
| Segmentation (DeepLabV3+) | âœ…                                     | âœ…                                        |
| Distance Calibration      | âœ…                                     | âœ… (based on track gauge)                 |
| Track-aware Object Fusion | âœ…                                     | âœ…                                        |
| Output Visualization      | âœ… Live Display                        | âœ… Saved PNGs                             |

---

## ğŸ“¦ Dependencies

Make sure the following libraries are installed:

```bash
pip install opencv-python torch torchvision ultralytics
pip install pyzed==4.0  # Only for ZED2 mode
```

Also ensure the ZED SDK is properly installed for real-time camera usage.

---

## ğŸ§  Models Used

| Model      | Purpose                 | Source                            |
|------------|-------------------------|-----------------------------------|
| YOLOv11    | Object detection        | `weights/yolo11n.pt`              |
| DeepLabV3+ | Rail track segmentation | Custom `.pth` file                |
| MiDaS      | Monocular depth         | `intel-isl/MiDaS` via `torch.hub` |

All models should be stored in the `weights/` directory.

---

## ğŸ§ª Usage
**1.** ğŸ“· Real-Time Depth Fusion (ZED2 Camera)
- Requires ZED2 device connected

```bash
cd depth
python scripts/run_depth_fusion_zed.py
```
- Press `q` to exit.
- Live detection, segmentation, and depth measurement will be displayed.

**2.** ğŸ–¼ï¸ Offline Depth Fusion (MiDaS)
- Uses MiDaS for monocular depth estimation.

```bash
cd depth
python scripts/run_depth_fusion_midas.py
```
- Input folder: `images/`
- Output folder: `outputs/`
- Results saved as `.png` files with visualized fusion.

---

## ğŸ“š Configuration
- Track Class ID: Set in both scripts (default: 12 for RailSem19)
- Detection Threshold: Default is 0.4
- Depth Calibration: Uses rail width (1.435m) to scale MiDaS depth
- Visual Overlay:
  - Track mask â†’ Yellow
  - Detected objects:
    - Red box: off-track
    - Green box: intersects track (with distance annotation)

---

## ğŸ› ï¸ Developer Notes
- `engine.py`: Implements `fuse_outputs()` â€” the main fusion logic reused across scripts.
- `models/loader.py`: Clean modular loaders for YOLO, DeepLabV3+, and MiDaS.
- `models/utils.py`: Core helpers for bounding box depth and calibration.
- `utils/visualization.py`: Draw boxes, labels, overlays with flexibility.

---

## ğŸ“š Acknowledgments

- [Torchvision Semantic Segmentation](https://github.com/qubvel-org/segmentation_models.pytorch)
- [Intel ISL MiDaS](https://github.com/isl-org/MiDaS)
- [ZED SDK](https://github.com/stereolabs/zed-sdk)
- [RailSem19 Dataset](https://www.wilddash.cc/railsem19)


---


