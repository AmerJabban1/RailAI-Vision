# RailAI-Vision: Deep Learning-Based Object Detection in Railway Environments (YOLO & Faster R-CNN, RailSem19)

This module contains pipelines for object detection in railway environments using multiple deep learning architectures, including **YOLOv8**, **YOLOv9**, **YOLOv11**, **YOLOv12**, and **Faster R-CNN**. Developed as part of a research project focused on enhancing railway safety through vision-based perception, the system supports both training from scratch and inference with pretrained models.

---

## ğŸ“ Folder Structure

```
detection/
â”œâ”€â”€ configs/                # YAML configuration files for each model (training setup)
â”œâ”€â”€ datasets/               # Local dataset in YOLO format (train/val/test + data.yaml)
â”œâ”€â”€ scripts/                # Unified training, validation, and prediction scripts
â”‚ â”œâ”€â”€ train.py              # General YOLO training
â”‚ â”œâ”€â”€ val.py                # YOLO evaluation
â”‚ â”œâ”€â”€ predict.py            # YOLO inference
â”‚ â””â”€â”€ train_fasterrcnn.py   # Faster R-CNN training
â”œâ”€â”€ utils/
â”‚ â”œâ”€â”€ dataset.py            # Faster R-CNN dataset loader
â”‚ â”œâ”€â”€ engine.py             # Faster R-CNN training engine
â”‚ â””â”€â”€ utils.py              # Logging, saving, helpers
â”œâ”€â”€ weights/                # Pretrained model weights (.pt/.pth)
â”œâ”€â”€ results/                # Evaluation outputs: confusion matrices, prediction samples, metrics
â”œâ”€â”€ requirements.txt        # Dependencies for the detection module
â””â”€â”€ README.md               # Documentation and usage guide
```

---

## ğŸ§° Environment

- Python â‰¥ 3.8
- Torch â‰¥ 2.0.0
- GPU with CUDA â‰¥ 11.7 recommended (for training)

---

## âš™ï¸ Installation

```bash
cd detection
pip install -r requirements.txt
```

---

## ğŸ“š Configuration

Each model has its own configuration file located in `configs/`, containing:
- Path to the model architecture or pretrained weights
- Training parameters (epochs, batch size, image size, etc.)
- Path to the `data.yaml` file

Example: `configs/yolov11.yaml`
Each configuration controls model-specific settings and can be passed as `--config` to all training/validation/inference scripts.


```yaml
model_architecture: yolov11s.pt
data_yaml: ./datasets/data.yaml
epochs: 50
imgsz: 640
batch: 16
device: 0
project: ./runs/train
name: yolov11
```

---

## ğŸš€ Usage
### ğŸ”· YOLO Models (YOLOv8, v9, v11, v12)
All YOLO models use the same script interface. Each one has a config in configs/.

#### ğŸ‹ï¸â€â™‚ï¸ Training

```bash
python scripts/train.py --config configs/yolov11.yaml
```

This command will train the selected model using the specified configuration.

---

#### ğŸ§ª Validation

```bash
python scripts/val.py \
  --model weights/yolov11.pt \
  --data datasets/data.yaml
```

This will evaluate the model on the validation split, providing metrics like mAP, precision, recall, and generating a confusion matrix.

---

#### ğŸ” Inference

```bash
python scripts/predict.py \
  --model weights/yolov11.pt \
  --source datasets/test/images \
  --conf 0.25
```

By default, results are saved under the `runs/detect/predict/` directory. You can customize the `--save-dir` argument if needed.

---

### ğŸ”¶ Faster R-CNN
Trained using PyTorchâ€™s torchvision.models.detection.

#### ğŸ‹ï¸â€â™‚ï¸ Training
```bash
python scripts/train_fasterrcnn.py --config configs/fasterrcnn.yaml
```

Internally uses dataset.py, engine.py, and utils.py to handle training loop and logging.

---

## ğŸ“Š Dataset Format

The dataset is organized in the standard YOLO format:

```
datasets/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ valid/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â””â”€â”€ data.yaml
```

Example `data.yaml`:

```yaml
train: ./datasets/train/images
val: ./datasets/valid/images
test: ./datasets/test/images

nc: 5
names: ['Obstacle', 'Person', 'Rail', 'Signal-and-Sign', 'Vehicle']
```

---

## ğŸ§  Pretrained Weights

The `weights/` directory contains pretrained `.pt` files for each model. To use a pretrained model directly for inference:

```bash
python scripts/predict.py --model weights/yolov8.pt --source datasets/test/images
```

If training is skipped, you can still use pretrained weights available in the `weights/` folder for inference.

---

## ğŸ“ˆ Output

Results from each model, including confusion matrices, training plots, and prediction samples, are stored in the `results/` directory.

### ğŸ” Example Detection Output

![PR Curve](results/PR_curve.png)
![Predictions](results/sample_predictions_1.png)

---

## ğŸ“ Notes
- âœ… All models trained on RailSem19 with 5 custom classes
- ğŸ§© Modular scripts support easy extension and experimentation
- ğŸ–¥ï¸ Designed for reproducible local execution (no cloud dependencies)
- ğŸ” Supports training from scratch or using pretrained weights
- âš¡ Works with CPU and GPU (CUDA) environments

---

## ğŸ“š Acknowledgments

- [Ultralytics YOLO](https://github.com/ultralytics/ultralytics)
- [TorchVision Models](https://docs.pytorch.org/vision/main/models.html)
- [RailSem19 Dataset](https://www.wilddash.cc/railsem19)

---